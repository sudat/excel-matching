#!/usr/bin/env python3
"""
ã‚¹ã‚­ãƒ¼ãƒæ¨è«–ç²¾åº¦ã®æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
"""

import requests
import json
import io
import pandas as pd

BASE_URL = "http://localhost:8000"

# æ§˜ã€…ãªãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
TEST_CASES = [
    {
        "name": "æ¨™æº–çš„ãªçµŒè²»ç²¾ç®—ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ",
        "data": {
            "ç”³è«‹æ—¥": ["2024/01/15", "2024/01/16", "2024/01/17"],
            "æ”¯æ‰•é‡‘é¡": [12500, 3500, 8000],
            "ç”³è«‹è€…æ°å": ["ç”°ä¸­å¤ªéƒ", "ä½è—¤èŠ±å­", "å±±ç”°æ¬¡éƒ"],
            "çµŒè²»ç¨®åˆ¥": ["äº¤é€šè²»", "é£Ÿäº‹ä»£", "å®¿æ³Šè²»"],
            "å‚™è€ƒ": ["æ–°å¹¹ç·šä»£", "ä¼šè­°å¼å½“", "ãƒ›ãƒ†ãƒ«ä»£"]
        },
        "expected": {
            "date_column": "ç”³è«‹æ—¥",
            "amount_column": "æ”¯æ‰•é‡‘é¡", 
            "person_column": "ç”³è«‹è€…æ°å",
            "category_column": "çµŒè²»ç¨®åˆ¥"
        }
    },
    {
        "name": "è‹±èªãƒ˜ãƒƒãƒ€ãƒ¼",
        "data": {
            "Date": ["2024-01-15", "2024-01-16", "2024-01-17"],
            "Amount": [12500, 3500, 8000],
            "Employee": ["Tanaka Taro", "Sato Hanako", "Yamada Jiro"],
            "Category": ["Transportation", "Meal", "Accommodation"],
            "Note": ["Train fare", "Meeting lunch", "Hotel"]
        },
        "expected": {
            "date_column": "Date",
            "amount_column": "Amount",
            "person_column": "Employee", 
            "category_column": "Category"
        }
    },
    {
        "name": "æ›–æ˜§ãªãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆæ¨è«–ãŒå›°é›£ï¼‰",
        "data": {
            "é …ç›®A": ["2024/01/15", "2024/01/16", "2024/01/17"],
            "é …ç›®B": [12500, 3500, 8000],
            "é …ç›®C": ["ç”°ä¸­", "ä½è—¤", "å±±ç”°"],
            "é …ç›®D": ["A", "B", "C"],
            "é …ç›®E": ["å‚™è€ƒ1", "å‚™è€ƒ2", "å‚™è€ƒ3"]
        },
        "expected": {
            "date_column": "é …ç›®A",  # æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¨è«–å¯èƒ½
            "amount_column": "é …ç›®B",  # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¨è«–å¯èƒ½
            "person_column": "é …ç›®C",  # äººåãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¨è«–å¯èƒ½
            "category_column": "é …ç›®D"  # å›°é›£ã ãŒé¸æŠè‚¢ã‹ã‚‰æ¨è«–
        }
    },
    {
        "name": "éƒ¨åˆ†çš„ã«æ¬ æã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³",
        "data": {
            "æ—¥ä»˜": ["2024/01/15", "2024/01/16", "2024/01/17"],
            "é‡‘é¡": [12500, 3500, 8000],
            "ãã®ä»–": ["æƒ…å ±1", "æƒ…å ±2", "æƒ…å ±3"],
            "è£œè¶³": ["ãƒ¡ãƒ¢1", "ãƒ¡ãƒ¢2", "ãƒ¡ãƒ¢3"]
        },
        "expected": {
            "date_column": "æ—¥ä»˜",
            "amount_column": "é‡‘é¡",
            "person_column": None,  # è©²å½“ãªã—
            "category_column": None  # è©²å½“ãªã—
        }
    }
]

def create_excel_from_data(data_dict):
    """è¾æ›¸ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    df = pd.DataFrame(data_dict)
    excel_buffer = io.BytesIO()
    df.to_excel(excel_buffer, index=False, engine='openpyxl')
    excel_buffer.seek(0)
    return excel_buffer.getvalue()

def run_full_flow(excel_data, case_name):
    """å®Œå…¨ãªãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã¦ã‚¹ã‚­ãƒ¼ãƒæ¨è«–çµæœã‚’å–å¾—"""
    
    # 1. Excelè§£æ
    files = {
        'file': (f'{case_name}.xlsx', excel_data, 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
    }
    
    response = requests.post(f"{BASE_URL}/api/parse-excel-sheets", files=files, timeout=30)
    if response.status_code != 200:
        return None, f"Excelè§£æå¤±æ•—: {response.status_code}"
    
    parse_result = response.json()
    session_id = parse_result["session_id"]
    sheet_name = parse_result["data"]["sheets"][0]["name"]
    
    # 2. è¡¨æ¤œå‡º
    response = requests.post(f"{BASE_URL}/api/excel-sheet-tables/{session_id}/{sheet_name}", timeout=30)
    if response.status_code != 200:
        return None, f"è¡¨æ¤œå‡ºå¤±æ•—: {response.status_code}"
    
    table_result = response.json()
    table_id = table_result["data"]["tables"][0]["table_id"]
    
    # 3. è¡¨é¸æŠ
    response = requests.post(f"{BASE_URL}/api/select-table/{session_id}/{table_id}", timeout=30)
    if response.status_code != 200:
        return None, f"è¡¨é¸æŠå¤±æ•—: {response.status_code}"
    
    select_result = response.json()
    headers = select_result["data"]["headers"]
    sample_records = select_result["data"]["sample_records"][:3]
    
    # 4. ã‚¹ã‚­ãƒ¼ãƒæ¨è«–
    sample_data = []
    for record in sample_records:
        row = [record.get(header, "") for header in headers]
        sample_data.append(row)
    
    inference_request = {
        "session_id": session_id,
        "headers": headers,
        "sample_data": sample_data
    }
    
    response = requests.post(f"{BASE_URL}/api/infer-schema", json=inference_request, 
                           headers={"Content-Type": "application/json"}, timeout=30)
    
    if response.status_code != 200:
        return None, f"ã‚¹ã‚­ãƒ¼ãƒæ¨è«–å¤±æ•—: {response.status_code}"
    
    return response.json(), None

def evaluate_inference_result(result, expected):
    """æ¨è«–çµæœã‚’è©•ä¾¡"""
    mappings = result["data"]["inference_result"]["mappings"]
    score = 0
    total = 0
    details = {}
    
    for column_type, expected_column in expected.items():
        total += 1
        mapping = mappings.get(column_type)
        
        if expected_column is None:
            # è©²å½“ãªã—ãŒæœŸå¾…ã•ã‚Œã‚‹å ´åˆ
            if mapping is None:
                score += 1
                details[column_type] = "âœ“ æ­£ã—ãã€Œè©²å½“ãªã—ã€ã¨åˆ¤å®š"
            else:
                details[column_type] = f"âœ— æœŸå¾…: ãªã—, å®Ÿéš›: {mapping.get('column_name')}"
        else:
            # ç‰¹å®šã®åˆ—ãŒæœŸå¾…ã•ã‚Œã‚‹å ´åˆ
            if mapping and mapping.get('column_name') == expected_column:
                score += 1
                confidence = mapping.get('confidence', 0)
                details[column_type] = f"âœ“ æ­£è§£ (ä¿¡é ¼åº¦: {confidence}%)"
            else:
                actual = mapping.get('column_name') if mapping else None
                details[column_type] = f"âœ— æœŸå¾…: {expected_column}, å®Ÿéš›: {actual}"
    
    accuracy = (score / total) * 100 if total > 0 else 0
    overall_confidence = result["data"]["inference_result"].get("overall_confidence", 0)
    
    return accuracy, overall_confidence, details

def test_inference_accuracy():
    """æ¨è«–ç²¾åº¦ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    
    print("=== ã‚¹ã‚­ãƒ¼ãƒæ¨è«–ç²¾åº¦æ¤œè¨¼ãƒ†ã‚¹ãƒˆ ===\n")
    
    total_accuracy = 0
    total_confidence = 0
    test_count = 0
    
    for i, test_case in enumerate(TEST_CASES, 1):
        print(f"ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i}: {test_case['name']}")
        print("-" * 50)
        
        # Excelãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        excel_data = create_excel_from_data(test_case['data'])
        
        # ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
        result, error = run_full_flow(excel_data, test_case['name'])
        
        if error:
            print(f"âœ— ã‚¨ãƒ©ãƒ¼: {error}")
            continue
        
        # è©•ä¾¡
        accuracy, confidence, details = evaluate_inference_result(result, test_case['expected'])
        
        print(f"æ¨è«–ç²¾åº¦: {accuracy:.1f}%")
        print(f"å…¨ä½“ä¿¡é ¼åº¦: {confidence}%")
        print("\nè©³ç´°çµæœ:")
        for column_type, detail in details.items():
            print(f"  {column_type}: {detail}")
        
        print()
        
        total_accuracy += accuracy
        total_confidence += confidence
        test_count += 1
    
    if test_count > 0:
        avg_accuracy = total_accuracy / test_count
        avg_confidence = total_confidence / test_count
        
        print("=" * 60)
        print("ğŸ¯ ç·åˆè©•ä¾¡")
        print(f"å¹³å‡æ¨è«–ç²¾åº¦: {avg_accuracy:.1f}%")
        print(f"å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.1f}%")
        print(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ•°: {test_count}/{len(TEST_CASES)}")
        
        if avg_accuracy >= 90:
            print("âœ… å„ªç§€: æ¨è«–ç²¾åº¦ãŒéå¸¸ã«é«˜ã„ã§ã™")
        elif avg_accuracy >= 75:
            print("âœ… è‰¯å¥½: æ¨è«–ç²¾åº¦ãŒè‰¯å¥½ã§ã™")
        elif avg_accuracy >= 50:
            print("âš ï¸  æ”¹å–„ä½™åœ°: æ¨è«–ç²¾åº¦ã®å‘ä¸ŠãŒå¿…è¦ã§ã™")
        else:
            print("âŒ è¦æ”¹å–„: æ¨è«–ç²¾åº¦ãŒä½ã™ãã¾ã™")

if __name__ == "__main__":
    test_inference_accuracy()